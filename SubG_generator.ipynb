{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Files: 100\n",
      "46072 rel cases out of 99 articles.\n",
      "#event_types 3173\n",
      "label_map [[0. 1.]\n",
      " [1. 0.]]   label_weights [9.398612811097511, 0.528094266523005]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from dataCopy1 import Data\n",
    "import numpy as np\n",
    "\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "remove_stop = False\n",
    "\n",
    "this_data = Data()\n",
    "this_data.load_hieve(file_direct='../datasets/hieve_processed/', remove_stop=True, num_case_limit=46072) \n",
    "#46072 is the case limit from the ACL19 paper\n",
    "\n",
    "#then you will have tuples (session_id, p_id, c_id, p_pos, c_pos, label) in this_data.data_cases\n",
    "# To get triples in the form (event1_surface, event2_surface, label):\n",
    "triples = [(this_data.text[int(x[0])][x[3]].lower(), this_data.text[int(x[0])][x[4]].lower(), x[5]) for x in this_data.data_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43621\n",
      "2451\n",
      "46072\n",
      "<class 'tuple'>\n",
      "('incidents', 'holding', 1)\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for i in triples:\n",
    "    if i[2] == 0:\n",
    "        count_0 += 1\n",
    "    if i[2] == 1:\n",
    "        count_1 += 1\n",
    "print(count_0)    # 43621 triples with false supersub relation\n",
    "print(count_1)    # 2451 triples with true supersub relation\n",
    "print(len(triples))\n",
    "print(type(triples[0]))\n",
    "print(triples[900])\n",
    "with open('./triples_46072.tsv', 'w') as f_triples:\n",
    "    for item in triples:\n",
    "        f_triples.write(str(item))\n",
    "        f_triples.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905\n"
     ]
    }
   ],
   "source": [
    "my_Ent_list = []\n",
    "for i in triples:\n",
    "    my_Ent_list.append(i[0])\n",
    "    my_Ent_list.append(i[1])\n",
    "    \n",
    "Ent_List_set = set(my_Ent_list) #List_set是另外一个列表，里面的内容是List里面的无重复项 \n",
    "print(len(Ent_List_set))\n",
    "with open('./HiEve_Ent_List_set.tsv', 'w') as f_Ent:\n",
    "    for item in Ent_List_set:\n",
    "        f_Ent.write(item)\n",
    "        f_Ent.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 18:09:09\n",
      "2019-09-23 18:09:37\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import node2vec\n",
    "import datetime\n",
    "\n",
    "def parse_args():\n",
    "\t'''\n",
    "\tParses the node2vec arguments.\n",
    "\t'''\n",
    "\tparser = argparse.ArgumentParser(description=\"Run node2vec.\")\n",
    "#graph/karate.edgelist\n",
    "\tparser.add_argument('--input', nargs='?', default='0Out.tsv',\n",
    "\t                    help='Input graph path')\n",
    "\n",
    "\tparser.add_argument('--output', nargs='?', default='emb/karate.emb',\n",
    "\t                    help='Embeddings path')\n",
    "\n",
    "\tparser.add_argument('--dimensions', type=int, default=128,\n",
    "\t                    help='Number of dimensions. Default is 128.')\n",
    "\n",
    "\tparser.add_argument('--walk-length', type=int, default=80,\n",
    "\t                    help='Length of walk per source. Default is 80.')\n",
    "\n",
    "\tparser.add_argument('--num-walks', type=int, default=10,\n",
    "\t                    help='Number of walks per source. Default is 10.')\n",
    "\n",
    "\tparser.add_argument('--window-size', type=int, default=10,\n",
    "                    \thelp='Context size for optimization. Default is 10.')\n",
    "\n",
    "\tparser.add_argument('--iter', default=1, type=int,\n",
    "                      help='Number of epochs in SGD')\n",
    "\n",
    "\tparser.add_argument('--workers', type=int, default=8,\n",
    "\t                    help='Number of parallel workers. Default is 8.')\n",
    "\n",
    "\tparser.add_argument('--p', type=float, default=1,\n",
    "\t                    help='Return hyperparameter. Default is 1.')\n",
    "\n",
    "\tparser.add_argument('--q', type=float, default=1,\n",
    "\t                    help='Inout hyperparameter. Default is 1.')\n",
    "\n",
    "\tparser.add_argument('--weighted', dest='weighted', action='store_true',\n",
    "\t                    help='Boolean specifying (un)weighted. Default is unweighted.')\n",
    "\tparser.add_argument('--unweighted', dest='unweighted', action='store_false')\n",
    "\tparser.set_defaults(weighted=False)\n",
    "\n",
    "\tparser.add_argument('--directed', dest='directed', action='store_true',\n",
    "\t                    help='Graph is (un)directed. Default is undirected.')\n",
    "\tparser.add_argument('--undirected', dest='undirected', action='store_false')\n",
    "\tparser.set_defaults(directed=False)\n",
    "\n",
    "\tparser.add_argument('--relation', dest='relationed', action='store_true',\n",
    "\t\t\t\t\t\thelp='Boolean specifying (un)relationed. Default is unrelationed.')\n",
    "\tparser.add_argument('--unrelation', dest='unrelationed', action='store_false')\n",
    "\tparser.set_defaults(relationed=False)\t\t\n",
    "\n",
    "\treturn parser.parse_args()\n",
    "\n",
    "def read_graph():\n",
    "\t'''\n",
    "\tReads the input network in networkx.\n",
    "\t'''\n",
    "\t'''\n",
    "\tif args.weighted:\n",
    "\t\tG = nx.read_edgelist(args.input, nodetype=str, data=(('weight',float),), create_using=nx.DiGraph())\n",
    "\telse:\n",
    "\t\tif args.relationed:\n",
    "\t\t\tG = nx.read_edgelist(args.input, nodetype=str, data=(('relation',str),), create_using=nx.DiGraph())\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\tG[edge[0]][edge[1]]['weight'] = 1\n",
    "\t\telse:\n",
    "\t\t\tG = nx.read_edgelist(args.input, nodetype=str, create_using=nx.DiGraph())\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\tG[edge[0]][edge[1]]['weight'] = 1\n",
    "\t\n",
    "\tif not args.directed:\n",
    "\t\tG = G.to_undirected()\n",
    "\t'''\n",
    "\tcount = 0\n",
    "\tG = nx.read_edgelist('0Out.tsv', nodetype=str, data=(('relation',str),), create_using=nx.DiGraph())\n",
    "\tfor edge in G.edges():\n",
    "\t\tG[edge[0]][edge[1]]['weight'] = 1\n",
    "\t\tcount = count+1\n",
    "\t\t#print(count)\n",
    "\treturn G\n",
    "\n",
    "\n",
    "'''\n",
    "Pipeline for representational learning for all nodes in a graph.\n",
    "'''\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "G = read_graph()\n",
    "print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 18:09:51\n",
      "50\n",
      "2019-09-23 18:11:17\n",
      "100\n",
      "2019-09-23 18:12:44\n",
      "150\n",
      "2019-09-23 18:14:13\n",
      "Error: Source shieldssearched is not in G\n",
      "200\n",
      "2019-09-23 18:15:41\n",
      "250\n",
      "2019-09-23 18:17:06\n",
      "300\n",
      "2019-09-23 18:18:39\n",
      "350\n",
      "2019-09-23 18:20:03\n",
      "400\n",
      "2019-09-23 18:21:30\n",
      "450\n",
      "2019-09-23 18:22:57\n",
      "500\n",
      "2019-09-23 18:24:28\n",
      "550\n",
      "2019-09-23 18:25:57\n",
      "600\n",
      "2019-09-23 18:27:25\n",
      "650\n",
      "2019-09-23 18:28:54\n",
      "700\n",
      "2019-09-23 18:30:25\n",
      "750\n",
      "2019-09-23 18:31:51\n",
      "800\n",
      "2019-09-23 18:33:15\n",
      "850\n",
      "2019-09-23 18:34:49\n",
      "900\n",
      "2019-09-23 18:36:19\n",
      "268082477\n",
      "297373\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "def subgraph_gen(cutoff):\n",
    "    neighbor = []\n",
    "    count_item = 0\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    for item in Ent_List_set:\n",
    "        try:\n",
    "            item_neighbors = nx.single_source_shortest_path_length(G, item, cutoff=cutoff)\n",
    "        except:\n",
    "            print(\"Error: Source \" + item + \" is not in G\")\n",
    "        else:\n",
    "            neighbor.append(list(item_neighbors.keys()))\n",
    "            count_item += 1\n",
    "\n",
    "        if count_item % 50 == 0:\n",
    "            print(count_item)\n",
    "            print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    merged = list(itertools.chain.from_iterable(neighbor))\n",
    "    print(len(merged))\n",
    "    merged_set = set(merged) #List_set是另外一个列表，里面的内容是\n",
    "    with open('./HiEve_merged_' + str(cutoff) + '_set.tsv', 'w') as f_out:\n",
    "        for item in merged_set:\n",
    "            f_out.write(item)\n",
    "            f_out.write(\"\\n\")\n",
    "\n",
    "    print(len(merged_set))\n",
    "    SubG = G.subgraph(list(merged_set))\n",
    "    nx.write_edgelist(SubG, 'SubG_' + str(cutoff) + '.tsv')\n",
    "    \n",
    "subgraph_gen(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
